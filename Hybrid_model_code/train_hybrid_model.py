import pandas as pd
import numpy as np
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from scipy.sparse import hstack, csr_matrix # Ù„Ø¯Ù…Ø¬ Ù…ØµÙÙˆÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙØ±Ù‚Ø©

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
# Ù…Ù„Ù Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ© (Ø§Ù„Ù†Ø§ØªØ¬ Ù…Ù† Farasa)
LINGUISTIC_FILE = "features_gemini_vs_human_augmented.csv"
# Ù…Ù„Ù Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø®Ø§Ù… (Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ N-Grams)
RAW_DATA_FILE = "merged_dataset_clean2.csv" 
COL_HUMAN = "human_collected_dataset"
COL_GEMINI = "gemini_rephrased_v2_5"

print("ğŸš€ Starting Hybrid Model Training (Farasa + N-Grams)...")

# --- 2. ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---

# Ø£. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ©
if not os.path.exists(LINGUISTIC_FILE):
    print(f"âŒ Error: Linguistic features file '{LINGUISTIC_FILE}' not found. Run previous pipeline first.")
    exit()

df_features = pd.read_csv(LINGUISTIC_FILE)
df_features.dropna(inplace=True)
X_linguistic = df_features.drop(columns=['label'])
y = df_features['label']
print(f"âœ… Loaded Linguistic Features: {len(X_linguistic)} samples.")


# Ø¨. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø®Ø§Ù… (Ù„Ù€ N-Grams)
try:
    df_raw = pd.read_csv(RAW_DATA_FILE)
    df_raw.columns = df_raw.columns.str.strip()
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø®Ø§Ù… Ø¨Ù†ÙØ³ Ø§Ù„ØªØ±ØªÙŠØ¨
    df_human = pd.DataFrame({'text': df_raw[COL_HUMAN]})
    df_ai = pd.DataFrame({'text': df_raw[COL_GEMINI]})
    df_text = pd.concat([df_human, df_ai], ignore_index=True)
    
    # ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø­Ø¬Ø§Ù…
    min_len = min(len(df_features), len(df_text))
    df_text = df_text.iloc[:min_len]
    X_linguistic = X_linguistic.iloc[:min_len]
    y = y.iloc[:min_len]
    
    X_text = df_text['text'].astype(str)
    print(f"âœ… Loaded Raw Text: {len(X_text)} samples (Synced).")

except Exception as e:
    print(f"âŒ Error loading raw text data: {e}")
    exit()

# 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ N-Grams
print("âš™ï¸  Generating N-Gram Features (TF-IDF Character N-grams)...")

tfidf = TfidfVectorizer(
    analyzer='char',
    ngram_range=(2, 5),
    max_features=20000, 
    min_df=5               
)
X_ngrams = tfidf.fit_transform(X_text)
print(f"âœ… N-Grams Features Shape: {X_ngrams.shape}")

# 4. Ø¯Ù…Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ (Hybrid Concatenation)
# Ù†Ø­ÙˆÙ„ Ø®ØµØ§Ø¦Øµ ÙØ±Ø§Ø³Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ù…ØªÙØ±Ù‚Ø© (Sparse Matrix) Ù„Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ TF-IDF
X_linguistic_sparse = csr_matrix(X_linguistic.values)

# Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø£ÙÙ‚ÙŠ (Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ© + Ø®ØµØ§Ø¦Øµ N-Grams)
X_hybrid = hstack([X_ngrams, X_linguistic_sparse])

print(f"âœ… Hybrid Dataset Shape: {X_hybrid.shape}")

# 5. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
X_train, X_test, y_train, y_test = train_test_split(
    X_hybrid, y, test_size=0.2, random_state=42, stratify=y
)

# 6. ØªØ¯Ø±ÙŠØ¨ XGBoost (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªÙŠ ÙˆØ¬Ø¯ØªÙ‡Ø§ Ø³Ø§Ø¨Ù‚Ø§Ù‹)
print("ğŸ¤– Training XGBoost Hybrid Model...")

model = XGBClassifier(
    n_estimators=500, 
    learning_rate=0.05, 
    max_depth=6, 
    random_state=42, 
    use_label_encoder=False, 
    eval_metric='logloss'
)
model.fit(X_train, y_train)

# 7. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("\n" + "="*50)
print(f"ğŸ† Final Hybrid Model Accuracy: {accuracy * 100:.2f}%")
print("="*50)

print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Human', 'AI']))