import pandas as pd
from farasa.pos import FarasaPOSTagger 
from tqdm import tqdm
import os
import sys

# --- 1. ุงูุฅุนุฏุงุฏุงุช ---
INPUT_FILE = "merged_dataset_clean2.csv"       # ูููู ุงููุฏูุฌ ุฐู ุงูู 4 ุฃุนูุฏุฉ
OUTPUT_FILE = "features_gemini_vs_human.csv"   # ุงูููู ุงููุงุชุฌ ููุชุฏุฑูุจ

# ุฃุณูุงุก ุงูุฃุนูุฏุฉ ุงูุชู ุณูุนุชูุฏ ุนูููุง ููุท
COL_HUMAN = "human_collected_dataset"
COL_GEMINI = "gemini_rephrased_v2_5"  # ูุนุชูุฏ ุนูู ูุฐุง ููุท ูู AI

print(f"๐ ุจุฏุก ุงุณุชุฎุฑุงุฌ ุงูุฎุตุงุฆุต: {COL_HUMAN} vs {COL_GEMINI}...")

# --- 2. ุชุญููู ุงูุจูุงูุงุช ---
if not os.path.exists(INPUT_FILE):
    print(f"โ ุฎุทุฃ: ุงูููู '{INPUT_FILE}' ุบูุฑ ููุฌูุฏ.")
    exit()

try:
    df = pd.read_csv(INPUT_FILE)
    print(f"๐ฅ ุชู ุชุญููู ุงูููู: {len(df)} ุตู.")
except Exception as e:
    print(f"โ ุฎุทุฃ ูู ูุฑุงุกุฉ ุงูููู: {e}")
    exit()

# ุงูุชุฃูุฏ ูู ูุฌูุฏ ุงูุฃุนูุฏุฉ
if COL_HUMAN not in df.columns or COL_GEMINI not in df.columns:
    print(f"โ ุงูุฃุนูุฏุฉ ุงููุทููุจุฉ ุบูุฑ ููุฌูุฏุฉ.\nุงูููุฌูุฏ: {df.columns.tolist()}")
    exit()

# --- 3. ุชุฌููุฒ ุงููููู (Text + Label) ---
print("๐ ุชุฌุงูู ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู (Qwen/Rewritten) ูุงูุชุฑููุฒ ุนูู Gemini...")

# ูุตูุต ุจุดุฑูุฉ (Label = 0)
df_human = pd.DataFrame({
    'text': df[COL_HUMAN],
    'label': 0
})

# ูุตูุต Gemini (Label = 1)
df_gemini = pd.DataFrame({
    'text': df[COL_GEMINI],
    'label': 1
})

# ุฏูุฌูู
df_final = pd.concat([df_human, df_gemini], ignore_index=True)

# ุชูุธูู ุงูููู ุงููุงุฑุบุฉ ูุงููุตูุต ุงููุตูุฑุฉ ุฌุฏุงู
df_final.dropna(subset=['text'], inplace=True)
df_final['text'] = df_final['text'].astype(str)
df_final = df_final[df_final['text'].str.strip().str.len() > 5] 

print(f"๐ ุฅุฌูุงูู ุงูุนููุงุช ูููุนุงูุฌุฉ: {len(df_final)} ุนููุฉ.")

# --- 4. ุชุดุบูู Farasa ---
print("โณ ุฌุงุฑู ุชุดุบูู Farasa POS Tagger...")
try:
    pos_tagger = FarasaPOSTagger(interactive=True)
    print("โ ุชู ุงูุชุดุบูู ุจูุฌุงุญ.")
except Exception as e:
    print(f"โ ูุดู ุชุดุบูู ููุชุจุฉ ูุฑุงุณุฉ: {e}")
    exit()

# --- 5. ุฏุงูุฉ ุงุณุชุฎุฑุงุฌ ุงูุฎุตุงุฆุต ---
def extract_features(text):
    features = {
        'NOUN_ratio': 0.0, 'VERB_ratio': 0.0, 'PART_ratio': 0.0, 'ADJ_ratio': 0.0,
        'NUM_ratio': 0.0, 'PRON_ratio': 0.0, 'DET_ratio': 0.0, 'PUNC_ratio': 0.0,
        'avg_word_len': 0.0, 'word_count': 0
    }
    
    if not text: return features

    try:
        tagged_text = pos_tagger.tag(text)
        if not tagged_text: return features
            
        tokens = tagged_text.split()
        total_tokens = len(tokens)
        features['word_count'] = total_tokens
        
        if total_tokens == 0: return features

        clean_words = []
        for t in tokens:
            if '/' in t: clean_words.append(t.rsplit('/', 1)[0])
            else: clean_words.append(t)
                
        if clean_words:
            features['avg_word_len'] = sum(len(w) for w in clean_words) / len(clean_words)

        for token in tokens:
            if '/' not in token: continue
            tag = token.rsplit('/', 1)[1]
            
            if tag.startswith('S') or tag == 'NOUN' or tag == 'FOREIGN': features['NOUN_ratio'] += 1
            elif tag.startswith('V'): features['VERB_ratio'] += 1
            elif tag.startswith('PART') or tag in ['CONJ', 'PREP', 'PRON', 'H']: features['PART_ratio'] += 1
            elif tag.startswith('ADJ'): features['ADJ_ratio'] += 1
            elif tag.startswith('NUM') or tag == 'NSUFF': features['NUM_ratio'] += 1
            elif tag.startswith('PRON'): features['PRON_ratio'] += 1
            elif tag.startswith('DET'): features['DET_ratio'] += 1
            elif tag == 'PUNC': features['PUNC_ratio'] += 1

        for key in features:
            if key not in ['word_count', 'avg_word_len']:
                features[key] = features[key] / total_tokens

    except Exception:
        pass
        
    return features

# --- 6. ุงูุชูููุฐ ---
print("โ๏ธ  ุฌุงุฑู ุงููุนุงูุฌุฉ...")
tqdm.pandas()
features_df = df_final['text'].progress_apply(extract_features).apply(pd.Series)
final_dataset = pd.concat([features_df, df_final['label']], axis=1)
final_dataset = final_dataset[final_dataset['word_count'] > 0]

# --- 7. ุงูุญูุธ ---
final_dataset.to_csv(OUTPUT_FILE, index=False)
print(f"\nโ ุชูุช ุงููููุฉ! ููู ุงูุฎุตุงุฆุต ุฌุงูุฒ: '{OUTPUT_FILE}'")