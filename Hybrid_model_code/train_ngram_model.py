import pandas as pd
import numpy as np
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
INPUT_FILE = "merged_dataset_clean2.csv"
COL_HUMAN = "human_collected_dataset"
COL_GEMINI = "gemini_rephrased_v2_5"

print("ğŸš€ Starting N-Grams Model Training...")

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
if not os.path.exists(INPUT_FILE):
    print(f"âŒ Error: File '{INPUT_FILE}' not found.")
    exit()

try:
    df = pd.read_csv(INPUT_FILE)
    df.columns = df.columns.str.strip()
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    if COL_HUMAN not in df.columns or COL_GEMINI not in df.columns:
        print("âŒ Columns not found.")
        exit()

    # ØªÙ†Ø¸ÙŠÙ Ø³Ø±ÙŠØ¹ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df.dropna(subset=[COL_HUMAN, COL_GEMINI], inplace=True)
    # Ø­Ø°Ù ØµÙÙˆÙ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù† ÙˆØ¬Ø¯Øª
    df = df[~df[COL_GEMINI].astype(str).str.contains("SKIPPED|ERROR", na=False)]

    print(f"ğŸ“¥ Loaded {len(df)} rows.")

    # Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Text + Label)
    df_human = pd.DataFrame({'text': df[COL_HUMAN], 'label': 0})
    df_gemini = pd.DataFrame({'text': df[COL_GEMINI], 'label': 1})
    df_final = pd.concat([df_human, df_gemini], ignore_index=True)
    
    # Ø­Ø°Ù Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
    df_final['text'] = df_final['text'].astype(str)
    df_final = df_final[df_final['text'].str.strip().str.len() > 10]

    print(f"ğŸ“Š Training samples: {len(df_final)}")

except Exception as e:
    print(f"âŒ Error: {e}")
    exit()

# --- 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ N-Grams (TF-IDF) ---
print("âš™ï¸  Vectorizing Text (Character N-Grams)...")

# Ù†Ø³ØªØ®Ø¯Ù… Character N-Grams (Ù…Ù† Ø­Ø±ÙÙŠÙ† Ø¥Ù„Ù‰ 5 Ø£Ø­Ø±Ù)
# Ù‡Ø°Ø§ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ ÙÙŠ ÙƒØ´Ù "Ø¨ØµÙ…Ø©" Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¢Ù„ÙŠØ©
tfidf = TfidfVectorizer(
    analyzer='char', 
    ngram_range=(2, 5),  # 2-5 Ø£Ø­Ø±Ù (ÙŠÙ„ØªÙ‚Ø· Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø§Øª ÙˆØ§Ù„Ù„Ø§Ø­Ù‚Ø§Øª ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø©)
    max_features=20000,  # Ù†Ø£Ø®Ø° Ø£Ù‡Ù… 20 Ø£Ù„Ù Ù†Ù…Ø· ÙÙ‚Ø·
    min_df=5             # Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ø¯Ø±Ø© Ø¬Ø¯Ø§Ù‹
)

X = tfidf.fit_transform(df_final['text'])
y = df_final['label']

print(f"âœ… Vectorization Complete. Features shape: {X.shape}")

# --- 4. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Logistic Regression) ---
# Logistic Regression Ù‡Ùˆ Ø§Ù„Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø°Ù‡Ø¨ÙŠ (Baseline) Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ùˆ TF-IDF
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("ğŸ¤– Training Logistic Regression Model...")
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# --- 5. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("\n" + "="*40)
print(f"ğŸ† N-Grams Model Accuracy: {accuracy * 100:.2f}%")
print("="*40)

print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Human', 'AI']))

# --- 6. ÙƒØ´Ù Ø§Ù„Ø£Ø³Ø±Ø§Ø±: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù€ N-Grams Ø§Ù„ØªÙŠ ØªÙØ¶Ø­ Ø§Ù„Ù€ AIØŸ ---
print("\nğŸ” Top 15 N-Grams Predicting AI vs Human:")
feature_names = tfidf.get_feature_names_out()
coefs = model.coef_[0]

# ØªØ±ØªÙŠØ¨ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø­Ø³Ø¨ ØªØ£Ø«ÙŠØ±Ù‡Ø§
# Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙˆØ¬Ø¨Ø© = Ù…Ø¤Ø´Ø± Ù‚ÙˆÙŠ Ø¹Ù„Ù‰ AI
# Ø£Ù‚Ù„ Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø© = Ù…Ø¤Ø´Ø± Ù‚ÙˆÙŠ Ø¹Ù„Ù‰ Human
top_positive_indices = np.argsort(coefs)[-15:][::-1]
top_negative_indices = np.argsort(coefs)[:15]

print("\nğŸ¤– Strongest Indicators for AI (Gemini):")
for idx in top_positive_indices:
    print(f"   '{feature_names[idx]}' (Score: {coefs[idx]:.2f})")

print("\nğŸ§‘ Strongest Indicators for Human:")
for idx in top_negative_indices:
    print(f"   '{feature_names[idx]}' (Score: {coefs[idx]:.2f})")