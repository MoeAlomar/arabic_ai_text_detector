import pandas as pd
from farasa.pos import FarasaPOSTagger 
from tqdm import tqdm
import os
import sys
import re
import warnings
import urllib3
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
INPUT_FILE = "merged_dataset_clean2.csv"       # Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯
FEATURES_FILE = "features_gemini_vs_human_augmented.csv" # Ù…Ù„Ù Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù†Ø§ØªØ¬ (Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯)

# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
COL_HUMAN = "human_collected_dataset"
COL_GEMINI = "gemini_rephrased_v2_5"

# Ø¥Ø³ÙƒØ§Øª Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

print(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù€ Pipeline Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {COL_HUMAN} vs {COL_GEMINI}")

# ==========================================
# PHASE 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ (Ù…Ø¹ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ø·ÙˆØ±Ø©)
# ==========================================

# Ù†ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù„Ù Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ù…Ø³Ø¨Ù‚Ø§Ù‹
if os.path.exists(FEATURES_FILE):
    print(f"âœ… Ù…Ù„Ù Ø§Ù„Ø®ØµØ§Ø¦Øµ '{FEATURES_FILE}' Ù…ÙˆØ¬ÙˆØ¯. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
    final_dataset = pd.read_csv(FEATURES_FILE)
else:
    print("âš™ï¸  Ù…Ù„Ù Ø§Ù„Ø®ØµØ§Ø¦Øµ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…...")
    
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Ø®Ø·Ø£: Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª '{INPUT_FILE}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        exit()

    try:
        df = pd.read_csv(INPUT_FILE)
        print(f"ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} ØµÙ.")
        
        # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ---
        df.columns = df.columns.str.strip()
        if COL_HUMAN not in df.columns or COL_GEMINI not in df.columns:
            print(f"âŒ Ø®Ø·Ø£: Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: [{COL_HUMAN}] Ø£Ùˆ [{COL_GEMINI}]")
            print(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {df.columns.tolist()}")
            exit()
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        exit()

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    # Ø­Ø°Ù Ø£Ø³Ø·Ø± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ (SKIPPED/ERROR)
    df = df[~df[COL_GEMINI].astype(str).str.contains("SKIPPED|ERROR", na=False)] 
    
    # Ø­Ø°Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    df.dropna(subset=[COL_HUMAN, COL_GEMINI], inplace=True)
    
    # Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù†Øµ + ØªØµÙ†ÙŠÙ)
    df_human = pd.DataFrame({'text': df[COL_HUMAN], 'label': 0})
    df_gemini = pd.DataFrame({'text': df[COL_GEMINI], 'label': 1})
    df_final = pd.concat([df_human, df_gemini], ignore_index=True)
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
    df_final['text'] = df_final['text'].astype(str)
    df_final = df_final[df_final['text'].str.strip().str.len() > 10]
    
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØµØ§Ù„Ø­Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(df_final)}")

    # ØªÙ‡ÙŠØ¦Ø© Farasa
    print("â³ ØªØ´ØºÙŠÙ„ Farasa...")
    try:
        pos_tagger = FarasaPOSTagger(interactive=True)
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ ÙØ±Ø§Ø³Ø©: {e}")
        exit()

    # Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ø§Ù„Ù…Ø·ÙˆØ±Ø©)
    def extract_features(text):
        features = {
            'NOUN_ratio': 0.0, 'VERB_ratio': 0.0, 'PART_ratio': 0.0, 'ADJ_ratio': 0.0,
            'NUM_ratio': 0.0, 'PRON_ratio': 0.0, 'DET_ratio': 0.0, 'PUNC_ratio': 0.0,
            'avg_word_len': 0.0, 'word_count': 0,
            'TTR_ratio': 0.0,       # Ø§Ù„ØªÙ†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø¬Ù…ÙŠ
            'avg_sentence_len': 0.0, # Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„Ø©
            'UNKNOWN_ratio': 0.0    # Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        }
        
        if not text: return features

        try:
            sentences = re.split(r'[.ØŸ!]', text)
            sentences = [s for s in sentences if s.strip()]
            
            tagged_text = pos_tagger.tag(text)
            if not tagged_text: return features
            
            tokens = tagged_text.split()
            total_tokens = len(tokens)
            features['word_count'] = total_tokens
            if total_tokens == 0: return features

            unknown_count = 0
            clean_words = []
            
            for token in tokens:
                if '/' not in token: 
                    unknown_count += 1
                    continue
                
                word = token.rsplit('/', 1)[0]
                tag = token.rsplit('/', 1)[1]
                clean_words.append(word)

                if tag.startswith('S') or tag in ['NOUN', 'FOREIGN']: features['NOUN_ratio'] += 1
                elif tag.startswith('V'): features['VERB_ratio'] += 1
                elif tag.startswith('PART') or tag in ['CONJ', 'PREP', 'PRON', 'H']: features['PART_ratio'] += 1
                elif tag.startswith('ADJ'): features['ADJ_ratio'] += 1
                elif tag.startswith('NUM') or tag == 'NSUFF': features['NUM_ratio'] += 1
                elif tag.startswith('PRON'): features['PRON_ratio'] += 1
                elif tag.startswith('DET'): features['DET_ratio'] += 1
                elif tag == 'PUNC': features['PUNC_ratio'] += 1

            if clean_words:
                features['avg_word_len'] = sum(len(w) for w in clean_words) / len(clean_words)
                features['TTR_ratio'] = len(set(clean_words)) / len(clean_words)
            if sentences:
                features['avg_sentence_len'] = sum(len(s.split()) for s in sentences) / len(sentences)
            
            features['UNKNOWN_ratio'] = unknown_count / total_tokens


            for key in features:
                if key not in ['word_count', 'avg_word_len', 'TTR_ratio', 'avg_sentence_len', 'UNKNOWN_ratio']:
                    features[key] = features[key] / total_tokens

        except Exception:
            pass
            
        return features

    print("âš™ï¸  Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ (Ù‚Ø¯ ÙŠØ£Ø®Ø° ÙˆÙ‚ØªØ§Ù‹)...")
    tqdm.pandas()
    features_df = df_final['text'].progress_apply(extract_features).apply(pd.Series)
    final_dataset = pd.concat([features_df, df_final['label']], axis=1)
    
    final_dataset = final_dataset[final_dataset['word_count'] > 0]
    
    final_dataset.to_csv(FEATURES_FILE, index=False)
    print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ '{FEATURES_FILE}'")


# ==========================================
# PHASE 2: ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (XGBoost Optimized)
# ==========================================

print("\nğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯Ù„ ÙˆØªØ­Ø³ÙŠÙ†Ù‡ (Grid Search)...")

final_dataset.dropna(inplace=True)
X = final_dataset.drop(columns=['label'])
y = final_dataset['label']

# ØªÙ‚Ø³ÙŠÙ… Ø·Ø¨Ù‚ÙŠ (Stratified Split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y
)

print("\nğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª (Grid Search) Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙØ¶Ù„...")

# Ø´Ø¨ÙƒØ© Ø¨Ø­Ø« Ù…Ø±ÙƒØ²Ø© ÙˆÙ‚ÙˆÙŠØ© Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ø­Ø§Ø¬Ø² 85%
param_grid_wide = {
    'n_estimators': [900, 1200, 1500],      # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø± Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ„Ø§Ù‚ÙŠ (Convergence)
    'learning_rate': [0.01, 0.03, 0.05],    # Ù…Ø¹Ø¯Ù„Ø§Øª ØªØ¹Ù„Ù… Ø¨Ø·ÙŠØ¦Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©
    'max_depth': [3, 4, 5],                 # Ø§Ù„ØªØ±ÙƒÙŠØ² Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ø£ÙØ¶Ù„ 
    'min_child_weight': [1, 3, 5],          # Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù€ Overfitting
    'subsample': [0.8],                     
    'colsample_bytree': [0.8],
}


xgb_base = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42,
    n_jobs=-1
)

grid_search = GridSearchCV(
    estimator=xgb_base, 
    param_grid=param_grid_wide, 
    scoring='accuracy', 
    cv=3, 
    verbose=1,
    n_jobs=-1
)

print("â³ Training model..")
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

print(f"\nğŸ† Best parameters: {grid_search.best_params_}")

# ØªÙ‚ÙŠÙŠÙ…
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("\n" + "="*40)
print(f"ğŸŒŸ final accuracy (Accuracy): {accuracy * 100:.2f}%")
print("="*40)

print("\nğŸ“‹ classification report :")
print(classification_report(y_test, y_pred, target_names=['Human', 'AI']))

# Ø£Ù‡Ù… Ø§Ù„Ø®ØµØ§Ø¦Øµ
print("\nğŸ” Top Feature:")
feature_important = best_model.get_booster().get_score(importance_type='gain')
keys = list(feature_important.keys())
values = list(feature_important.values())
importance_df = pd.DataFrame(data=values, index=keys, columns=["score"]).sort_values(by="score", ascending=False)
print(importance_df.head(12))